{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511f4b73",
   "metadata": {},
   "source": [
    "# 2.) ADS Project - SwissSuperLeague"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f03b65",
   "metadata": {},
   "source": [
    "Verwendete Quellen:\n",
    "- Hands On ML with Scikit-Learn, Keras und Tensorflow, A.Geron, O'Reilly - gemäss Vorlesung\n",
    "- Decision Tree Regression in 6 Steps with Python: https://medium.com/pursuitnotes/decision-tree-regression-in-6-steps-with-python-1a1c5aa2ee16\n",
    "- Day 19 - Regression trees: http://alumni.media.mit.edu/~tpminka/courses/36-350.2001/lectures/day19/\n",
    "- Scrape FBref data: https://github.com/parth1902/Scrape-FBref-data/blob/master/README.md\n",
    "- StatsBomb Release Free 2020/21 FA Women’s Super League Data & Updated ‘R’ Guide: https://statsbomb.com/articles/soccer/statsbomb-release-free-2020-21-fa-womens-super-league-data-updated-r-guide/\n",
    "- Udacity Capstone Project: https://github.com/Matheuskempa/My_Udacity_Capstone\n",
    "- Code aus Vorlesungswoche 8\n",
    "- Codes aus Woche 7: Exploratory data analysis and vizualizations von DSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6898e8",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dda2ed",
   "metadata": {},
   "source": [
    "Zuerst importieren wir die relevanten libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8940bd",
   "metadata": {},
   "source": [
    "Einlesen der von zuvor gescrapten Daten aus csv. file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17565328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Swiss.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdee86c",
   "metadata": {},
   "source": [
    "Daten anschauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e83a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe4323",
   "metadata": {},
   "source": [
    "Anzahl Daten-Zeilen pro Spalte sowie Datentypen anschauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45732b",
   "metadata": {},
   "source": [
    "Zwischenschritt: Spalte 'Score' trennen in zwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056ef74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Für Score Spalte '-' entfernen\n",
    "df[\"Score\"] = df[\"Score\"].replace(\"\\–\", \"\", regex=True)\n",
    "\n",
    "# Resultat in Heim und Auswärts Spalte trennen\n",
    "df['HomeScore'] = df['Score'].str[0:1]\n",
    "df['HomeScore'] = df['HomeScore'].astype(str).astype(float)\n",
    "df['AwayScore'] = df['Score'].str[1:2].astype(str)\n",
    "df['AwayScore'] = df['AwayScore'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eaa7e9",
   "metadata": {},
   "source": [
    "Daten anschauen mit getrennten Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0adc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ddcfb",
   "metadata": {},
   "source": [
    "Zwischenschritt 2: Neue 'Ergebnis' Spalte schaffen mittels der getrennten Score (HomeScore/AwayScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335404d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Neue Spalte mit Niederlage(0)/Sieg(1)/Unentschieden(2)\n",
    "df['Ergebnis'] = \"2\"\n",
    "df['Ergebnis'] = df['Ergebnis'].astype(str).astype(float)\n",
    "\n",
    "# Unterdrücken von SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#for Schleife unm die spalte \"Ergebnis\" zu befüllen\n",
    "for index, row in df.iterrows():\n",
    "    home = row['HomeScore']\n",
    "    away = row['AwayScore']\n",
    "    if home < away:\n",
    "        df[\"Ergebnis\"][index]  = 0\n",
    "    elif home > away:\n",
    "        df[\"Ergebnis\"][index] = 1\n",
    "    elif ((home-away) == 0):\n",
    "        df[\"Ergebnis\"][index]  = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe582c4a",
   "metadata": {},
   "source": [
    "Zwischenschritt 2: Überprüfen ob 'Ergebnis' Spalte sichtbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79524839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f170c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8818df",
   "metadata": {},
   "source": [
    "Checken für duplicated columns -> page breaks in unserem table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e7d26",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59682ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55590c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d5edf",
   "metadata": {},
   "source": [
    "Checken für NA cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262b193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c41829",
   "metadata": {},
   "source": [
    "Wir berücksichtigen nur Zeilen mit einem Score weil die anderen Zeilen NA oder keine gespielten Spiele sind und daher unwichtig sind für uns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Score'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087d9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf77b2",
   "metadata": {},
   "source": [
    "Droppen von irrelevanten Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21054360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Notes', 'Match Report', 'Referee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f201fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0890e7",
   "metadata": {},
   "source": [
    "## EDA - Exploratory Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6606db9",
   "metadata": {},
   "source": [
    "Zuerst importieren wir die relevanten libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0f2d0",
   "metadata": {},
   "source": [
    "Hier visualiseren wir die nummerischen Stats um interessante Insgights zu bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52785ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e70a0",
   "metadata": {},
   "source": [
    "Boxplot der Attendance Verteilung zeigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da868145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.ticklabel_format(style='plain')\n",
    "sns.boxplot(x=df['Attendance'], color=\"green\")\n",
    "print('Mean of Attendance: ' +str(int(np.mean(df['Attendance']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a273c2",
   "metadata": {},
   "source": [
    "Histogramm der Häufigkeit der 'Attendance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe68b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(8,4) )\n",
    "plt.xticks(fontsize=12, rotation=0)\n",
    "plt.yticks(fontsize=12, rotation=0)\n",
    "n, bins, patches = plt.hist(x=df['Attendance'], bins=20, color='#3d85c6', alpha=1, rwidth=0.95)\n",
    "plt.axvline(df['Attendance'].mean(), color='r', linestyle='dashed', linewidth=3)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.title('Histogram of Attendance', fontsize=16, pad=10)\n",
    "plt.ticklabel_format(style='plain')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Attendance', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Frequency', fontsize=14, labelpad=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e545d",
   "metadata": {},
   "source": [
    "Spider chart um die durchschnittliche Besucherzahlen der verschiedenen Stadien zu vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11fb51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spider= df[['Venue','Attendance']]\n",
    "df_spider_2 = df_spider.groupby(df_spider['Venue']).mean()\n",
    "fig = px.line_polar(df_spider_2, r='Attendance', \n",
    "                    theta=df_spider_2.index,  \n",
    "                    line_close=True\n",
    "                   )\n",
    "fig.update_layout(width=500,height=370)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9bdb3d",
   "metadata": {},
   "source": [
    "## Machine Learning modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c08126",
   "metadata": {},
   "source": [
    "Die Daten sind nun gescrapet und visualisiert worden. Nun werden sie in einem ML Modell weiter verwertet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ab21f",
   "metadata": {},
   "source": [
    "Zuerst importieren wir die relevanten libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1905d",
   "metadata": {},
   "source": [
    "Variablen welche nicht relevant sind für das ML Modell droppen wir von unserem Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328bec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eingabe = df.drop(columns=['Wk','Score', 'Day', 'Date', 'Time','Home','Away','Venue','Ergebnis'])\n",
    "eingabe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c66865",
   "metadata": {},
   "source": [
    "Wir definieren zuerst die dependent und independent Variabeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(eingabe)\n",
    "y = df[\"Ergebnis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08917890",
   "metadata": {},
   "source": [
    "Wir bereiten die Daten vor in dem wie sie in Test und Training Datensätze splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf517b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1caa2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14c361",
   "metadata": {},
   "source": [
    "Jetzt executen wir RandomForestClassifier ML Algortihmus für unsere Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27755b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RF = RandomForestClassifier (n_estimators = 100, random_state = 30)\n",
    "model_RF.fit (X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a2e78",
   "metadata": {},
   "source": [
    "Als nächsten machen wir eine Prediction für unser Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249dab33",
   "metadata": {},
   "source": [
    "Wir zeigen die Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062296f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy = \", accuracy_score(y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545b3e8",
   "metadata": {},
   "source": [
    "Jetzt zeigen wir die Verteilung der Wichtigkeit der einzelnen Features im Random Forest ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f33779",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(x.columns)\n",
    "feature_imp = pd.Series(model_RF.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "#print (model.feature_importances_)\n",
    "print (feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fcd65",
   "metadata": {},
   "source": [
    "Visualisierung der Wichtigkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b64e8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importance = model_RF.feature_importances_\n",
    "\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "for i,j in zip(importance,eingabe.columns):\n",
    "    list_1.append(str(j))\n",
    "    list_2.append(i)\n",
    "    \n",
    "df_name = pd.DataFrame(list_1,columns=[\"Feature\"])\n",
    "df_number = pd.DataFrame(list_2,columns=[\"Wichtigkeit\"])\n",
    "\n",
    "df_ranking = pd.concat([df_name, df_number], axis=1)\n",
    "df_final = df_ranking.sort_values(\"Wichtigkeit\",ascending=False).reset_index(drop=True)\n",
    "df_final.Column = df_final.Feature.astype(str)\n",
    "f, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(x=\"Wichtigkeit\", y=\"Feature\", data=df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70942569",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499ece8",
   "metadata": {},
   "source": [
    "Jetzt trainieren wir unser Model noch mittels eines NeuralNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4df942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN = tf.keras.models.Sequential()\n",
    "model_NN.add(tf.keras.layers.Flatten())\n",
    "model_NN.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model_NN.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model_NN.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model_NN.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_NN.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb09b82",
   "metadata": {},
   "source": [
    "Hier die Accuracy zum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966cd57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loss, val_acc = model_NN.evaluate (X_test, y_test)\n",
    "print (val_loss, val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
